{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset via the libary \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# load dataset from huggingface using the package datasets\n",
    "ds = load_dataset(\"yuvidhepe/us-accidents-updated\")\n",
    "\n",
    "# limit the number of lines in the data set at an early stage\n",
    "small_ds = ds['train'].select(range(100))\n",
    "\n",
    "# copying the dataset to panda\n",
    "TrafficAccidents_preprocessed = small_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the impact on traffic in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ‘Start_Time’ and ‘End_Time’ to datetime format\n",
    "TrafficAccidents_preprocessed['Start_Time'] = pd.to_datetime(TrafficAccidents_preprocessed['Start_Time'])\n",
    "TrafficAccidents_preprocessed['End_Time'] = pd.to_datetime(TrafficAccidents_preprocessed['End_Time'])\n",
    "\n",
    "# Calculate the difference in seconds and add it as a new column\n",
    "TrafficAccidents_preprocessed['Duration_Seconds'] = (TrafficAccidents_preprocessed['End_Time'] - TrafficAccidents_preprocessed['Start_Time']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete all discussed columns from the data set according to the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to be removed\n",
    "columns_to_drop = [\n",
    "    'ID', 'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Description',\n",
    "    'City', 'County', 'State', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp',\n",
    "    'Wind_Chill(F)', 'Precipitation(in)', 'Bump', 'Roundabout', 'Station', 'Turning_Loop',\n",
    "    'Sunrise_Sunset', 'Nautical_Twilight', 'Astronomical_Twilight', 'Source'\n",
    "]\n",
    "\n",
    "# Drop the specified columns\n",
    "TrafficAccidents_preprocessed = TrafficAccidents_preprocessed.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation of columns with numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Columns to be scaled\n",
    "columns_to_scale = ['Distance(mi)', 'Temperature(F)', 'Humidity(%)', \n",
    "                    'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Duration_Seconds']\n",
    "\n",
    "# Instance of the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the StandardScaler to the defined columns\n",
    "TrafficAccidents_preprocessed[columns_to_scale] = scaler.fit_transform(TrafficAccidents_preprocessed[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
