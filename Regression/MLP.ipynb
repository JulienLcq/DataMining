{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for Regression - MLPRegressor with Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MLP: {'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "MLP Regression - MAE: 0.558781513102367\n",
      "MLP Regression - MSE: 0.5984186657173319\n",
      "Accuracy: 0.4610\n",
      "R-squared (R²): -1.5587\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.14      0.21      0.17      9362\n",
      "           2       0.82      0.45      0.58    873568\n",
      "           3       0.18      0.57      0.28    188164\n",
      "           4       0.17      0.14      0.16     27219\n",
      "\n",
      "    accuracy                           0.46   1098313\n",
      "   macro avg       0.33      0.34      0.30   1098313\n",
      "weighted avg       0.69      0.46      0.52   1098313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy.special import softmax\n",
    "\n",
    "train_data = pd.read_csv(\"Train_Set.csv\")\n",
    "val_data = pd.read_csv(\"Validation_Set.csv\")\n",
    "test_data = pd.read_csv('Test_Set.csv')\n",
    "\n",
    "X = train_data.drop(columns=[\"Severity\"])\n",
    "y = train_data[\"Severity\"]\n",
    "\n",
    "X_test = test_data.drop(columns=[\"Severity\"])\n",
    "y_test = test_data[\"Severity\"]\n",
    "\n",
    "combined_data = pd.concat([train_data, val_data], axis=0)\n",
    "X_combined = combined_data.drop(columns=[\"Severity\"])\n",
    "y_combined = combined_data[\"Severity\"]\n",
    "\n",
    "# Create an indicator array for the validation set split\n",
    "split_index = [-1] * len(train_data) + [0] * len(val_data)\n",
    "predefined_split = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "# Define the parameter grid for MLPRegressor\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(100,)],\n",
    "    'alpha': [0.0001],\n",
    "    'learning_rate': ['constant']\n",
    "}\n",
    "\n",
    "# Perform Grid Search for Hyperparameter Optimization\n",
    "grid_search_mlp = RandomizedSearchCV(\n",
    "    MLPRegressor(max_iter=200, random_state=42),\n",
    "    param_grid_mlp,\n",
    "    n_iter=1,\n",
    "    cv=predefined_split,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_mlp.fit(X_combined, y_combined)  \n",
    "\n",
    "# Get the best model and parameters\n",
    "best_mlp_model = grid_search_mlp.best_estimator_\n",
    "print(\"Best parameters for MLP:\", grid_search_mlp.best_params_)\n",
    "\n",
    "# Predictions using the optimized MLPRegressor\n",
    "y_pred_mlp = best_mlp_model.predict(X_test)\n",
    "y_pred_mlp_rounded = y_pred_mlp.round().astype(int)\n",
    "\n",
    "# Map predictions to the nearest valid class\n",
    "valid_classes = np.array([1, 2, 3, 4])\n",
    "\n",
    "# Function to find the nearest class\n",
    "def map_to_nearest_class(predictions, valid_classes):\n",
    "    return valid_classes[np.argmin(np.abs(predictions[:, np.newaxis] - valid_classes), axis=1)]\n",
    "\n",
    "# Adjust predictions to the nearest valid class\n",
    "y_pred_mlp_mapped = map_to_nearest_class(y_pred_mlp, valid_classes)\n",
    "\n",
    "# Binarize the true labels for ROC curve (with valid classes only)\n",
    "y_test_binarized = label_binarize(y_test, classes=valid_classes)\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "\n",
    "# Evaluation with mapped predictions\n",
    "mae_mlp = mean_absolute_error(y_test, y_pred_mlp_mapped)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp_mapped)\n",
    "accuracy = accuracy_score(y_test, y_pred_mlp_mapped)\n",
    "r2 = r2_score(y_test, y_pred_mlp_mapped)\n",
    "classification_report_str = classification_report(y_test, y_pred_mlp_mapped, labels=valid_classes)\n",
    "\n",
    "# Output the corrected results\n",
    "print(f\"MLP Regression - MAE: {mae_mlp}\")\n",
    "print(f\"MLP Regression - MSE: {mse_mlp}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
